In the tradition of "awesome" (curated) lists, this is a list of references and
code for doing deep learning in Haskell. PRs welcome.

# Articles

## 2016

- [Computing symbolic gradient vectors with plain Haskell](http://blog.aloni.org/posts/symbolic-gradients-with-plain-haskell/)
-- Dan Aloni

- [Practical Dependent Types in Haskell 2: Existential Neural Networks and Types at Runtime](https://blog.jle.im/)
-- Justin Le

- [Practical Dependent Types in Haskell: Type-Safe Neural Networks (Part 1)](https://blog.jle.im/entry/practical-dependent-types-in-haskell-1.html)
-- Justin Le

## 2015

- [Neural Networks, Types, and Functional Programming](http://colah.github.io/posts/2015-09-NN-Types-FP/)
-- Christopher Olah

## 2013

- [Backpropogation is Just Steepest Descent with Automatic Differentiation](https://idontgetoutmuch.wordpress.com/2013/10/13/backpropogation-is-just-steepest-descent-with-automatic-differentiation-2/)

## Older

- [Get a Brain](https://crypto.stanford.edu/~blynn/haskell/brain.html)

# Libraries

- [backprop](http://hackage.haskell.org/package/backprop)
- [dnngraph](https://github.com/ajtulloch/dnngraph)
- [deeplearning-hs](https://hackage.haskell.org/package/deeplearning-hs)
- [grenade](https://github.com/HuwCampbell/grenade)
- [lambdanet](https://hackage.haskell.org/package/LambdaNet)
- [neural](http://hackage.haskell.org/package/neural)
- [tensorflow](https://github.com/tensorflow/haskell)
